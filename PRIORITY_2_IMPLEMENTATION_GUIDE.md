# ğŸš€ ä¼˜å…ˆçº§ 2 å®ç°æŒ‡å—

**é¢„è®¡å·¥ä½œé‡**: 5-8 å°æ—¶
**éš¾åº¦**: ä¸­ç­‰
**ä¾èµ–**: ä¼˜å…ˆçº§ 1 å…¨éƒ¨å®Œæˆ âœ…

---

## ğŸ“‹ ä¼˜å…ˆçº§ 2 ä»»åŠ¡æ¸…å•

### 3 ä¸ªæ ¸å¿ƒä»»åŠ¡

| # | ä»»åŠ¡ | é¢„è®¡æ—¶é—´ | éš¾åº¦ | æ–‡ä»¶ |
|---|------|---------|------|------|
| 1 | é”™è¯¯æ¢å¤ï¼ˆerror recoveryï¼‰ | 1-2h | ä¸­ | `src/core/error_recovery.rs` |
| 2 | æµå¼å¤„ç†ä¼˜åŒ–ï¼ˆstreaming optimizationï¼‰ | 2-3h | ä¸­ | `src/core/streaming_optimizer.rs` |
| 3 | Token è®¡ç®—ï¼ˆtoken calculationï¼‰ | 1-2h | ä½ | `src/core/token_calculator.rs` |

**æ€»è®¡**: 4-7 å°æ—¶ï¼Œé¢„è®¡ 500+ è¡Œæ–°å¢ä»£ç 

---

## 1ï¸âƒ£ é”™è¯¯æ¢å¤ï¼ˆError Recoveryï¼‰

### ğŸ“ æ–‡ä»¶: `src/core/error_recovery.rs` (æ–°å»º)

### ğŸ¯ ç›®æ ‡
å®ç°å®Œå–„çš„é”™è¯¯æ¢å¤æœºåˆ¶ï¼Œæ”¯æŒç‰¹å®šé”™è¯¯ç±»å‹çš„å¤„ç†å’Œè‡ªåŠ¨é™çº§ã€‚

### ğŸ“Š è®¾è®¡æ–¹æ¡ˆ

```rust
/// é”™è¯¯ç±»å‹åˆ†ç±»
#[derive(Debug, Clone)]
pub enum RecoverableError {
    RateLimitExceeded,      // é€Ÿç‡é™åˆ¶
    TokenLimitExceeded,     // Token é™åˆ¶
    ModelNotAvailable,      // æ¨¡å‹ä¸å¯ç”¨
    NetworkError,           // ç½‘ç»œé”™è¯¯
    TimeoutError,           // è¶…æ—¶
    InvalidResponse,        // æ— æ•ˆå“åº”
    PartialResponse,        // éƒ¨åˆ†å“åº”
}

/// æ¢å¤ç­–ç•¥
#[derive(Debug, Clone)]
pub enum RecoveryStrategy {
    Retry,                  // é‡è¯•
    Fallback,               // é™çº§åˆ°å¤‡é€‰æ¨¡å‹
    ReduceContext,          // å‡å°‘ä¸Šä¸‹æ–‡
    CompressHistory,        // å‹ç¼©å†å²
    SkipTools,              // è·³è¿‡å·¥å…·è°ƒç”¨
    Abort,                  // ä¸­æ­¢
}

/// é”™è¯¯æ¢å¤å™¨
pub struct ErrorRecovery {
    error_handlers: HashMap<RecoverableError, Vec<RecoveryStrategy>>,
    fallback_models: Vec<String>,
}

impl ErrorRecovery {
    pub fn new() -> Self { ... }
    
    /// å¤„ç†é”™è¯¯å¹¶è¿”å›æ¢å¤ç­–ç•¥
    pub async fn handle_error(
        &self,
        error: RecoverableError,
        context: &ConversationContext,
    ) -> Result<RecoveryStrategy> { ... }
    
    /// æ‰§è¡Œæ¢å¤ç­–ç•¥
    pub async fn execute_recovery(
        &self,
        strategy: RecoveryStrategy,
        engine: &mut ConversationEngine,
    ) -> Result<ProcessedResponse> { ... }
}
```

### ğŸ”„ é”™è¯¯å¤„ç†æµç¨‹

```
å‘ç”Ÿé”™è¯¯
    â†“
è¯†åˆ«é”™è¯¯ç±»å‹
    â†“
æŸ¥è¯¢æ¢å¤ç­–ç•¥
    â†“
æ‰§è¡Œæ¢å¤æ“ä½œ
    â”œâ”€ Retry â†’ é‡è¯•è¯·æ±‚
    â”œâ”€ Fallback â†’ åˆ‡æ¢æ¨¡å‹
    â”œâ”€ ReduceContext â†’ ç§»é™¤éƒ¨åˆ†ä¸Šä¸‹æ–‡
    â”œâ”€ CompressHistory â†’ å‹ç¼©å†å²
    â”œâ”€ SkipTools â†’ ç¦ç”¨å·¥å…·è°ƒç”¨
    â””â”€ Abort â†’ è¿”å›é”™è¯¯
    â†“
é‡æ–°å°è¯•æˆ–è¿”å›ç»“æœ
```

### ğŸ’¡ å®ç°è¦ç‚¹

1. **é€Ÿç‡é™åˆ¶å¤„ç†**
   ```rust
   RecoverableError::RateLimitExceeded => {
       // ç­‰å¾…æŒ‡å®šæ—¶é—´åé‡è¯•
       tokio::time::sleep(Duration::from_secs(retry_after)).await;
       RecoveryStrategy::Retry
   }
   ```

2. **æ¨¡å‹ä¸å¯ç”¨å¤„ç†**
   ```rust
   RecoverableError::ModelNotAvailable => {
       // åˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹
       RecoveryStrategy::Fallback
   }
   ```

3. **Token é™åˆ¶å¤„ç†**
   ```rust
   RecoverableError::TokenLimitExceeded => {
       // å‹ç¼©å†å²æˆ–å‡å°‘ä¸Šä¸‹æ–‡
       RecoveryStrategy::CompressHistory
   }
   ```

4. **ç½‘ç»œé”™è¯¯å¤„ç†**
   ```rust
   RecoverableError::NetworkError => {
       // æŒ‡æ•°é€€é¿é‡è¯•
       RecoveryStrategy::Retry
   }
   ```

### ğŸ“ å•å…ƒæµ‹è¯•

```rust
#[cfg(test)]
mod tests {
    #[tokio::test]
    async fn test_rate_limit_recovery() { ... }
    
    #[tokio::test]
    async fn test_model_fallback() { ... }
    
    #[tokio::test]
    async fn test_context_reduction() { ... }
}
```

---

## 2ï¸âƒ£ æµå¼å¤„ç†ä¼˜åŒ–ï¼ˆStreaming Optimizationï¼‰

### ğŸ“ æ–‡ä»¶: `src/core/streaming_optimizer.rs` (æ–°å»º)

### ğŸ¯ ç›®æ ‡
ä¼˜åŒ–æµå¼å“åº”å¤„ç†ï¼Œæé«˜æ€§èƒ½å’Œç”¨æˆ·ä½“éªŒã€‚

### ğŸ“Š è®¾è®¡æ–¹æ¡ˆ

```rust
/// æµå¼ä¼˜åŒ–å™¨
pub struct StreamingOptimizer {
    chunk_size: usize,              // å—å¤§å°
    buffer_threshold: usize,        // ç¼“å†²é˜ˆå€¼
    flush_interval_ms: u64,         // åˆ·æ–°é—´éš”
    enable_compression: bool,       // å¯ç”¨å‹ç¼©
}

/// ä¼˜åŒ–çš„æµå¼äº‹ä»¶
#[derive(Debug, Clone)]
pub struct OptimizedStreamEvent {
    pub event_type: StreamEventType,
    pub content: String,
    pub chunk_index: usize,
    pub total_chunks: Option<usize>,
    pub timestamp: DateTime<Local>,
    pub processing_time_ms: u64,
}

impl StreamingOptimizer {
    pub fn new() -> Self { ... }
    
    /// ä¼˜åŒ–æµå¼å“åº”
    pub async fn optimize_stream<S>(
        &self,
        stream: S,
    ) -> Result<impl Stream<Item = OptimizedStreamEvent>>
    where
        S: Stream<Item = StreamEvent>,
    { ... }
    
    /// æ‰¹é‡å¤„ç†äº‹ä»¶
    pub fn batch_events(
        &self,
        events: Vec<StreamEvent>,
    ) -> Vec<OptimizedStreamEvent> { ... }
    
    /// è®¡ç®—ååé‡
    pub fn calculate_throughput(&self, events: &[OptimizedStreamEvent]) -> f64 { ... }
}
```

### ğŸ”„ ä¼˜åŒ–æµç¨‹

```
åŸå§‹æµ
    â†“
åˆ†å—å¤„ç† (chunk_size)
    â†“
ç¼“å†²ç®¡ç† (buffer_threshold)
    â†“
å¯é€‰å‹ç¼© (enable_compression)
    â†“
å®šæ—¶åˆ·æ–° (flush_interval_ms)
    â†“
ä¼˜åŒ–çš„æµ
```

### ğŸ’¡ å®ç°è¦ç‚¹

1. **æ™ºèƒ½åˆ†å—**
   ```rust
   pub fn chunk_stream(&self, content: String) -> Vec<String> {
       content
           .chars()
           .collect::<Vec<_>>()
           .chunks(self.chunk_size)
           .map(|chunk| chunk.iter().collect())
           .collect()
   }
   ```

2. **ç¼“å†²ç®¡ç†**
   ```rust
   pub fn should_flush(&self, buffer_size: usize) -> bool {
       buffer_size >= self.buffer_threshold
   }
   ```

3. **æ€§èƒ½ç›‘æ§**
   ```rust
   pub fn track_performance(&self, event: &OptimizedStreamEvent) {
       // è®°å½•å¤„ç†æ—¶é—´ã€ååé‡ç­‰æŒ‡æ ‡
   }
   ```

4. **èƒŒå‹å¤„ç†**
   ```rust
   pub async fn apply_backpressure(&self, queue_size: usize) {
       if queue_size > self.buffer_threshold {
           tokio::time::sleep(Duration::from_millis(10)).await;
       }
   }
   ```

### ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æ”¹è¿› |
|------|-------|-------|------|
| å¹³å‡å»¶è¿Ÿ | 50ms | 20ms | 60% â†“ |
| ååé‡ | 1000 events/s | 5000 events/s | 400% â†‘ |
| å†…å­˜å ç”¨ | 10MB | 5MB | 50% â†“ |
| CPU ä½¿ç”¨ | 25% | 10% | 60% â†“ |

### ğŸ“ å•å…ƒæµ‹è¯•

```rust
#[cfg(test)]
mod tests {
    #[tokio::test]
    async fn test_stream_chunking() { ... }
    
    #[tokio::test]
    async fn test_buffer_management() { ... }
    
    #[tokio::test]
    async fn test_throughput_calculation() { ... }
}
```

---

## 3ï¸âƒ£ Token è®¡ç®—ï¼ˆToken Calculationï¼‰

### ğŸ“ æ–‡ä»¶: `src/core/token_calculator.rs` (æ–°å»º)

### ğŸ¯ ç›®æ ‡
å®ç°ç²¾ç¡®çš„ Token è®¡ç®—ï¼Œæ”¯æŒå¤šç§æ¨¡å‹å’Œç¼–ç æ–¹å¼ã€‚

### ğŸ“Š è®¾è®¡æ–¹æ¡ˆ

```rust
/// Token è®¡ç®—å™¨
pub struct TokenCalculator {
    model: String,
    encoding: TokenEncoding,
}

/// Token ç¼–ç æ–¹å¼
#[derive(Debug, Clone)]
pub enum TokenEncoding {
    Cl100kBase,             // GPT-3.5/GPT-4
    P50kBase,               // GPT-3
    R50kBase,               // ç¼–ç 
    Custom(String),         // è‡ªå®šä¹‰
}

/// Token ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct TokenStats {
    pub total_tokens: usize,
    pub input_tokens: usize,
    pub output_tokens: usize,
    pub tool_tokens: usize,
    pub system_tokens: usize,
}

impl TokenCalculator {
    pub fn new(model: impl Into<String>) -> Self { ... }
    
    /// è®¡ç®—æ–‡æœ¬çš„ Token æ•°
    pub fn count_tokens(&self, text: &str) -> usize { ... }
    
    /// è®¡ç®—æ¶ˆæ¯çš„ Token æ•°
    pub fn count_message_tokens(&self, message: &Message) -> usize { ... }
    
    /// è®¡ç®—å¯¹è¯çš„ Token æ•°
    pub fn count_conversation_tokens(&self, messages: &[Message]) -> TokenStats { ... }
    
    /// ä¼°ç®—æˆæœ¬
    pub fn estimate_cost(
        &self,
        stats: &TokenStats,
        input_price: f64,
        output_price: f64,
    ) -> f64 { ... }
    
    /// æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
    pub fn exceeds_limit(&self, tokens: usize, limit: usize) -> bool {
        tokens > limit
    }
}
```

### ğŸ”„ Token è®¡ç®—æµç¨‹

```
è¾“å…¥æ–‡æœ¬
    â†“
é€‰æ‹©ç¼–ç æ–¹å¼
    â†“
åˆ†è¯å¤„ç†
    â†“
è®¡ç®— Token æ•°
    â†“
ç»Ÿè®¡ä¿¡æ¯
    â†“
æˆæœ¬ä¼°ç®—
```

### ğŸ’¡ å®ç°è¦ç‚¹

1. **ç²¾ç¡®çš„ Token è®¡æ•°**
   ```rust
   pub fn count_tokens(&self, text: &str) -> usize {
       match self.encoding {
           TokenEncoding::Cl100kBase => {
               // ä½¿ç”¨ tiktoken åº“æˆ–è‡ªå®šä¹‰ç®—æ³•
               text.split_whitespace().count() + text.matches(|c: char| !c.is_alphanumeric()).count()
           }
           TokenEncoding::P50kBase => { ... }
           _ => text.len() / 4, // ç®€å•ä¼°ç®—
       }
   }
   ```

2. **æ¶ˆæ¯ Token è®¡æ•°**
   ```rust
   pub fn count_message_tokens(&self, message: &Message) -> usize {
       let content_tokens = self.count_tokens(&message.content);
       let role_tokens = 4; // è§’è‰²æ ‡è®°
       content_tokens + role_tokens
   }
   ```

3. **å¯¹è¯ Token ç»Ÿè®¡**
   ```rust
   pub fn count_conversation_tokens(&self, messages: &[Message]) -> TokenStats {
       let mut stats = TokenStats::default();
       for message in messages {
           let tokens = self.count_message_tokens(message);
           match message.role {
               MessageRole::User => stats.input_tokens += tokens,
               MessageRole::Assistant => stats.output_tokens += tokens,
               MessageRole::System => stats.system_tokens += tokens,
           }
       }
       stats.total_tokens = stats.input_tokens + stats.output_tokens + stats.system_tokens;
       stats
   }
   ```

4. **æˆæœ¬ä¼°ç®—**
   ```rust
   pub fn estimate_cost(
       &self,
       stats: &TokenStats,
       input_price: f64,
       output_price: f64,
   ) -> f64 {
       (stats.input_tokens as f64 * input_price / 1000.0) +
       (stats.output_tokens as f64 * output_price / 1000.0)
   }
   ```

### ğŸ“Š æ”¯æŒçš„æ¨¡å‹

| æ¨¡å‹ | ç¼–ç æ–¹å¼ | è¾“å…¥ä»·æ ¼ | è¾“å‡ºä»·æ ¼ |
|------|---------|---------|---------|
| GPT-4 | cl100k_base | $0.03/1K | $0.06/1K |
| GPT-3.5 | cl100k_base | $0.0005/1K | $0.0015/1K |
| Gemini 2.5 | custom | $0.075/1M | $0.30/1M |
| Claude 3 | custom | $0.003/1K | $0.015/1K |

### ğŸ“ å•å…ƒæµ‹è¯•

```rust
#[cfg(test)]
mod tests {
    #[test]
    fn test_token_counting() { ... }
    
    #[test]
    fn test_message_tokens() { ... }
    
    #[test]
    fn test_cost_estimation() { ... }
}
```

---

## ğŸ› ï¸ å®ç°æ­¥éª¤

### ç¬¬ 1 æ­¥ï¼šé”™è¯¯æ¢å¤ï¼ˆ1-2 å°æ—¶ï¼‰

1. åˆ›å»º `src/core/error_recovery.rs`
2. å®šä¹‰é”™è¯¯ç±»å‹å’Œæ¢å¤ç­–ç•¥
3. å®ç° `ErrorRecovery` ç»“æ„ä½“
4. æ·»åŠ å•å…ƒæµ‹è¯•
5. é›†æˆåˆ° `ConversationEngine`

**å…³é”®ä»£ç **:
```rust
// åœ¨ conversation_engine.rs ä¸­
pub async fn process_input_with_recovery(
    &mut self,
    input: String,
) -> Result<ProcessedResponse> {
    match self.process_input_complete(input).await {
        Ok(response) => Ok(response),
        Err(e) => {
            let error = RecoverableError::from_string(&e);
            let strategy = self.error_recovery.handle_error(error, &context).await?;
            self.error_recovery.execute_recovery(strategy, self).await
        }
    }
}
```

### ç¬¬ 2 æ­¥ï¼šæµå¼å¤„ç†ä¼˜åŒ–ï¼ˆ2-3 å°æ—¶ï¼‰

1. åˆ›å»º `src/core/streaming_optimizer.rs`
2. å®ç°æµå¼ä¼˜åŒ–å™¨
3. æ·»åŠ æ€§èƒ½ç›‘æ§
4. æ·»åŠ å•å…ƒæµ‹è¯•
5. é›†æˆåˆ°æµå¼å¤„ç†

**å…³é”®ä»£ç **:
```rust
// åœ¨ streaming.rs ä¸­
pub async fn optimize_stream(&self) -> Result<impl Stream<Item = OptimizedStreamEvent>> {
    let optimizer = StreamingOptimizer::new();
    optimizer.optimize_stream(self.receiver).await
}
```

### ç¬¬ 3 æ­¥ï¼šToken è®¡ç®—ï¼ˆ1-2 å°æ—¶ï¼‰

1. åˆ›å»º `src/core/token_calculator.rs`
2. å®ç° Token è®¡ç®—å™¨
3. æ·»åŠ æˆæœ¬ä¼°ç®—
4. æ·»åŠ å•å…ƒæµ‹è¯•
5. é›†æˆåˆ°æ¶ˆæ¯å†å²

**å…³é”®ä»£ç **:
```rust
// åœ¨ message_history.rs ä¸­
pub fn calculate_tokens(&mut self) -> TokenStats {
    let calculator = TokenCalculator::new("gpt-4");
    calculator.count_conversation_tokens(&self.get_messages())
}
```

---

## ğŸ“Š é›†æˆæ£€æŸ¥æ¸…å•

- [ ] åˆ›å»º `src/core/error_recovery.rs`
- [ ] å®ç° `ErrorRecovery` ç»“æ„ä½“
- [ ] æ·»åŠ é”™è¯¯æ¢å¤å•å…ƒæµ‹è¯•
- [ ] é›†æˆåˆ° `ConversationEngine`
- [ ] åˆ›å»º `src/core/streaming_optimizer.rs`
- [ ] å®ç° `StreamingOptimizer` ç»“æ„ä½“
- [ ] æ·»åŠ æµå¼ä¼˜åŒ–å•å…ƒæµ‹è¯•
- [ ] é›†æˆåˆ°æµå¼å¤„ç†
- [ ] åˆ›å»º `src/core/token_calculator.rs`
- [ ] å®ç° `TokenCalculator` ç»“æ„ä½“
- [ ] æ·»åŠ  Token è®¡ç®—å•å…ƒæµ‹è¯•
- [ ] é›†æˆåˆ°æ¶ˆæ¯å†å²
- [ ] æ›´æ–° `src/core/mod.rs` å¯¼å‡ºæ–°æ¨¡å—
- [ ] è¿è¡Œ `cargo check` éªŒè¯ç¼–è¯‘
- [ ] è¿è¡Œ `cargo test` éªŒè¯æµ‹è¯•

---

## ğŸ“š æ–‡æ¡£

| æ–‡æ¡£ | è¯´æ˜ |
|------|------|
| `PRIORITY_2_IMPLEMENTATION_GUIDE.md` | æœ¬æ–‡æ¡£ |
| `PRIORITY_1_STATUS_REPORT.md` | ä¼˜å…ˆçº§ 1 å®ŒæˆæŠ¥å‘Š |
| `GEMINI_CLI_CORE_ANALYSIS.md` | æ ¸å¿ƒåˆ†æ |

---

## ğŸ¯ é¢„æœŸæˆæœ

### ä»£ç ç»Ÿè®¡
- æ–°å¢ä»£ç ï¼š500+ è¡Œ
- å•å…ƒæµ‹è¯•ï¼š30+ ä¸ªæµ‹è¯•ç”¨ä¾‹
- æ–‡æ¡£ï¼š200+ è¡Œ

### åŠŸèƒ½å®Œæ•´æ€§
âœ… å®Œå–„çš„é”™è¯¯æ¢å¤æœºåˆ¶
âœ… ä¼˜åŒ–çš„æµå¼å¤„ç†æ€§èƒ½
âœ… ç²¾ç¡®çš„ Token è®¡ç®—å’Œæˆæœ¬ä¼°ç®—

### æ€§èƒ½æ”¹è¿›
âœ… å¹³å‡å»¶è¿Ÿé™ä½ 60%
âœ… ååé‡æå‡ 400%
âœ… å†…å­˜å ç”¨é™ä½ 50%

---

## ğŸš€ ä¸‹ä¸€æ­¥

å®Œæˆä¼˜å…ˆçº§ 2 åï¼Œå¯ä»¥å¼€å§‹ä¼˜å…ˆçº§ 3 çš„å¯é€‰åŠŸèƒ½ï¼š
1. æ—¥å¿—å’Œé¥æµ‹ç³»ç»Ÿ
2. å•å…ƒæµ‹è¯•å®Œæ•´è¦†ç›–
3. æ€§èƒ½ä¼˜åŒ–

---

**é¢„è®¡å®Œæˆæ—¶é—´**: 5-8 å°æ—¶
**éš¾åº¦**: ä¸­ç­‰
**ä¼˜å…ˆçº§**: ğŸ”´ é«˜

